{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# some magic so that the notebook will reload external python modules;\n",
    "# see https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import hydra\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "# from pytorch_lightning.plugins import DDPPlugin\n",
    "from avg_ckpts import ensemble\n",
    "from datamodule.data_module import DataModule\n",
    "from datamodule.grid_dataset import GridDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule.transforms import VideoTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataset/DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule.grid_dataset import GridDataset\n",
    "root_dir = \"/ssd_scratch/cvit/vanshg/preprocessed_grid/video\"\n",
    "label_path = \"/ssd_scratch/cvit/vanshg/preprocessed_grid/labels/s1_label.csv\"\n",
    "data_size = 0.8\n",
    "\n",
    "dataset = GridDataset(root_dir, label_path, VideoTransform(\"train\"), data_size=data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "torch.Size([75, 1, 88, 88])\n",
      "tensor([ 941,  969,  811, 2033, 4742, 3291])\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(type(data))\n",
    "    print(data['input'].shape)\n",
    "    print(data['target'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Path : /ssd_scratch/cvit/vanshg/vansh_phrases/train_labels.txt, exists = True\n",
      "Size of self.video_list: 70\n"
     ]
    }
   ],
   "source": [
    "from datamodule.phrase_dataset import PhraseDataset\n",
    "from datamodule.data_module_phrase import pad, collate_pad\n",
    "\n",
    "def _dataloader(ds, collate_fn):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        batch_size=5,\n",
    "        num_workers=1,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "root_dir = \"/ssd_scratch/cvit/vanshg/vansh_phrases\"\n",
    "label_path = \"/ssd_scratch/cvit/vanshg/vansh_phrases/train_labels.txt\"\n",
    "data_size = 1.0\n",
    "\n",
    "dataset = PhraseDataset(root_dir, label_path, VideoTransform('train'), data_size=data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['inputs', 'input_lengths', 'targets', 'target_lengths'])\n",
      "torch.Size([5, 1, 8])\n",
      "torch.Size([5, 70, 1, 88, 88])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2bed6d4400>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2bed6d4400>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2bed6d4400>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home2/vanshg/miniconda3/envs/lip-reading/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['inputs', 'input_lengths', 'targets', 'target_lengths'])\n",
      "torch.Size([5, 1, 7])\n",
      "torch.Size([5, 68, 1, 88, 88])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "<class 'dict'>\n",
      "dict_keys(['inputs', 'input_lengths', 'targets', 'target_lengths'])\n",
      "torch.Size([5, 1, 7])\n",
      "torch.Size([5, 67, 1, 88, 88])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "<class 'dict'>\n",
      "dict_keys(['inputs', 'input_lengths', 'targets', 'target_lengths'])\n",
      "torch.Size([5, 1, 8])\n",
      "torch.Size([5, 66, 1, 88, 88])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "<class 'dict'>\n",
      "dict_keys(['inputs', 'input_lengths', 'targets', 'target_lengths'])\n",
      "torch.Size([5, 1, 8])\n",
      "torch.Size([5, 63, 1, 88, 88])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "<class 'dict'>\n",
      "dict_keys(['inputs', 'input_lengths', 'targets', 'target_lengths'])\n",
      "torch.Size([5, 1, 9])\n",
      "torch.Size([5, 65, 1, 88, 88])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = _dataloader(dataset, collate_pad)\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i > 5:\n",
    "        break\n",
    "    print(type(batch))\n",
    "    print(batch.keys())\n",
    "    print(batch['targets'].shape)\n",
    "    print(batch['inputs'].shape)\n",
    "    print(batch['input_lengths'].shape)\n",
    "    print(batch['target_lengths'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "torch.Size([1, 53, 88, 88])\n",
      "tensor([2550, 3231,  544, 2408,  276,  129,  228,  175])\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(type(data))\n",
    "    print(data['input'].shape)\n",
    "    print(data['target'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "label_path = \"/ssd_scratch/cvit/vanshg/vansh_phrases/phrases.json\"\n",
    "dst_train_label_path = \"/ssd_scratch/cvit/vanshg/vansh_phrases/train_phrases_60.json\"\n",
    "dst_test_label_path = \"/ssd_scratch/cvit/vanshg/vansh_phrases/test_phrases_40.json\"\n",
    "\n",
    "f = open(label_path, 'r')\n",
    "\n",
    "video_list = json.load(f)\n",
    "rng = random.Random(69)\n",
    "rng.shuffle(video_list)\n",
    "\n",
    "train_video_list = video_list[:60]\n",
    "test_video_list = video_list[60:]\n",
    "print(len(train_video_list))\n",
    "print(len(test_video_list))\n",
    "\n",
    "with open(dst_train_label_path, 'w') as file:\n",
    "    json.dump(train_video_list, file)\n",
    "\n",
    "with open(dst_test_label_path, 'w') as file:\n",
    "    json.dump(test_video_list, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some magic so that the notebook will reload external python modules;\n",
    "# see https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import hydra\n",
    "import cv2\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "\n",
    "from datamodule.av_dataset import cut_or_pad\n",
    "from datamodule.transforms import AudioTransform, VideoTransform\n",
    "from hydra import initialize, compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferencePipeline(torch.nn.Module):\n",
    "    def __init__(self, cfg, detector=\"retinaface\"):\n",
    "        super(InferencePipeline, self).__init__()\n",
    "        self.modality = cfg.data.modality\n",
    "        if self.modality in [\"audio\", \"audiovisual\"]:\n",
    "            self.audio_transform = AudioTransform(subset=\"test\")\n",
    "        if self.modality in [\"video\", \"audiovisual\"]:\n",
    "            if detector == \"mediapipe\":\n",
    "                from preparation.detectors.mediapipe.detector import LandmarksDetector\n",
    "                from preparation.detectors.mediapipe.video_process import VideoProcess\n",
    "                self.landmarks_detector = LandmarksDetector()\n",
    "                self.video_process = VideoProcess(convert_gray=False)\n",
    "            elif detector == \"retinaface\":\n",
    "                from preparation.detectors.retinaface.detector import LandmarksDetector\n",
    "                from preparation.detectors.retinaface.video_process import VideoProcess\n",
    "                self.landmarks_detector = LandmarksDetector(device=\"cuda:0\")\n",
    "                self.video_process = VideoProcess(convert_gray=False)\n",
    "            self.video_transform = VideoTransform(subset=\"test\")\n",
    "\n",
    "        if cfg.data.modality in [\"audio\", \"video\"]:\n",
    "            from lightning import ModelModule\n",
    "        elif cfg.data.modality == \"audiovisual\":\n",
    "            from lightning_av import ModelModule\n",
    "        self.modelmodule = ModelModule(cfg)\n",
    "        self.modelmodule.model.load_state_dict(torch.load(cfg.pretrained_model_path, map_location=lambda storage, loc: storage))\n",
    "        self.modelmodule.eval()\n",
    "\n",
    "\n",
    "    def forward(self, data_filename):\n",
    "        data_filename = os.path.abspath(data_filename)\n",
    "        assert os.path.isfile(data_filename), f\"data_filename: {data_filename} does not exist.\"\n",
    "\n",
    "        if self.modality in [\"audio\", \"audiovisual\"]:\n",
    "            audio, sample_rate = self.load_audio(data_filename)\n",
    "            audio = self.audio_process(audio, sample_rate)\n",
    "            audio = audio.transpose(1, 0)\n",
    "            audio = self.audio_transform(audio)\n",
    "\n",
    "        if self.modality in [\"video\", \"audiovisual\"]:\n",
    "            video = self.load_video(data_filename)\n",
    "            landmarks = self.landmarks_detector(video)\n",
    "            video = torch.tensor(self.video_process(video, landmarks)) # (T, H, W, C)\n",
    "            video = video.permute(0, 3, 1, 2) # (T, C, H, W)\n",
    "            print(f\"video.shape = {video.shape}\")\n",
    "            video = self.video_transform(video)\n",
    "            print(f\"shape of video after transformation: {video.shape}\")\n",
    "\n",
    "            return video\n",
    "        if self.modality == \"video\":\n",
    "            with torch.no_grad():\n",
    "                self.modelmodule = self.modelmodule.to(device)\n",
    "                transcript = self.modelmodule(video)\n",
    "        elif self.modality == \"audio\":\n",
    "            with torch.no_grad():\n",
    "                transcript = self.modelmodule(audio)\n",
    "\n",
    "        elif self.modality == \"audiovisual\":\n",
    "            print(len(audio), len(video))\n",
    "            assert 530 < len(audio) // len(video) < 670, \"The video frame rate should be between 24 and 30 fps.\"\n",
    "\n",
    "            rate_ratio = len(audio) // len(video)\n",
    "            if rate_ratio == 640:\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"The ideal video frame rate is set to 25 fps, but the current frame rate ratio, calculated as {len(video)*16000/len(audio):.1f}, which may affect the performance.\")\n",
    "                audio = cut_or_pad(audio, len(video) * 640)\n",
    "            with torch.no_grad():\n",
    "                transcript = self.modelmodule(video, audio)\n",
    "\n",
    "        return transcript\n",
    "\n",
    "    def load_audio(self, data_filename):\n",
    "        waveform, sample_rate = torchaudio.load(data_filename, normalize=True)\n",
    "        return waveform, sample_rate\n",
    "\n",
    "    def load_video(self, data_filename):\n",
    "        return torchvision.io.read_video(data_filename, pts_unit=\"sec\")[0].numpy()\n",
    "\n",
    "    def audio_process(self, waveform, sample_rate, target_sample_rate=16000):\n",
    "        if sample_rate != target_sample_rate:\n",
    "            waveform = torchaudio.functional.resample(\n",
    "                waveform, sample_rate, target_sample_rate\n",
    "            )\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decoder': 0.9, 'ctc': 0.1, 'lm': 0.3, 'length_bonus': 0.0}\n",
      "init: self.device: cpu\n",
      "video.shape = torch.Size([49, 96, 96, 3])\n",
      "shape of video after transformation: torch.Size([1, 49, 88, 88])\n",
      "video.shape after transform = torch.Size([1, 49, 88, 88])\n",
      "video.min = -2.1237075328826904 | video.max = 1.7740938663482666\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"configs\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.data.modality = 'video'\n",
    "    cfg.pretrained_model_path = \"./checkpoints/lrs3/models/LRS3_V_WER19.1/model.pth\"\n",
    "    cfg.file_path = \"/home/vanshg/play/IIITH/research-cvit/lip-reading/Visual_Speech_Recognition_for_Multiple_Languages/data/test/0QVXdEOiCw8/00001.mp4\"\n",
    "\n",
    "    pipeline = InferencePipeline(cfg)\n",
    "    video = pipeline(cfg.file_path)\n",
    "    print(f\"video.shape after transform = {video.shape}\")\n",
    "    print(f\"video.min = {video.min()} | video.max = {video.max()}\")\n",
    "    # video = video.to('cpu')\n",
    "    # print(video.shape, video.device)\n",
    "\n",
    "    # with open('processed_video1.pkl', 'wb') as file:\n",
    "    #     torch.save(video, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49, 88, 88]) cpu torch.float32\n",
      "torch.Size([1, 49, 88, 88]) cpu torch.float32\n"
     ]
    }
   ],
   "source": [
    "with open('processed_video.pkl', 'rb') as file:\n",
    "    other_video = torch.load(file)\n",
    "\n",
    "print(video.shape, video.device, video.dtype)\n",
    "print(other_video.shape, other_video.device, other_video.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(video, other_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.shape = torch.Size([1, 49, 88, 88])\n",
      "Number of hypothesis: 132\n",
      "Prediction 0: IT WASN'T REALLY ALL LIKE THIS | scores: {'decoder': -4.883006572723389, 'ctc': -9.339526176452637, 'lm': -27.997802734375}\n",
      "Prediction 1: IT WASN'T VERY COOL LIKE THIS | scores: {'decoder': -5.048012733459473, 'ctc': -7.849823474884033, 'lm': -29.284236907958984}\n",
      "Prediction 2: IT WASN'T QUITE ALL LIKE THIS | scores: {'decoder': -6.687277793884277, 'ctc': -11.480616569519043, 'lm': -26.260738372802734}\n",
      "Prediction 3: IT WASN'T REALLY AT ALL LIKE THIS | scores: {'decoder': -7.503573417663574, 'ctc': -13.569295883178711, 'lm': -25.910791397094727}\n",
      "Prediction 4: IT WASN'T REALLY QUITE LIKE THIS | scores: {'decoder': -7.709312915802002, 'ctc': -11.921098709106445, 'lm': -26.63516616821289}\n",
      "Prediction 5: IT WASN'T VERY COOL LOOKING THINGS | scores: {'decoder': -5.334903717041016, 'ctc': -14.818465232849121, 'lm': -35.50229263305664}\n",
      "Prediction 6: I WASN'T REALLY AT ALL LIKE THIS | scores: {'decoder': -8.112814903259277, 'ctc': -14.372286796569824, 'lm': -27.979228973388672}\n",
      "Prediction 7: IT WASN'T VERY COOL OR LIKE THIS | scores: {'decoder': -6.012252330780029, 'ctc': -11.021333694458008, 'lm': -36.17854309082031}\n",
      "Prediction 8: I WASN'T TRYING TO LOOK LIKE THIS | scores: {'decoder': -8.172547340393066, 'ctc': -18.51236343383789, 'lm': -28.09740447998047}\n",
      "Prediction 9: IT WASN'T VERY COOL LOOKING AT THINGS | scores: {'decoder': -6.158985137939453, 'ctc': -16.712207794189453, 'lm': -35.99525833129883}\n",
      "Prediction 10: I WASN'T QUITE SURE WHAT I FELT | scores: {'decoder': -8.956730842590332, 'ctc': -28.478681564331055, 'lm': -23.947805404663086}\n",
      "Prediction 11: IT WASN'T VERY GOOD OR LIKE THIS | scores: {'decoder': -8.315644264221191, 'ctc': -15.171801567077637, 'lm': -32.133304595947266}\n",
      "Prediction 12: I WASN'T TRYING TO WALK AWAY LIKE THIS | scores: {'decoder': -7.531175136566162, 'ctc': -23.293455123901367, 'lm': -32.94108963012695}\n",
      "Prediction 13: IT WASN'T VERY COOL LOOKING AT THIS | scores: {'decoder': -7.484671115875244, 'ctc': -14.704949378967285, 'lm': -36.164451599121094}\n",
      "Prediction 14: I WASN'T VERY GOOD AT WORKING THINGS | scores: {'decoder': -8.057342529296875, 'ctc': -26.532255172729492, 'lm': -30.97176742553711}\n",
      "Prediction 15: IT WASN'T VERY COOL AT ALL LIKE THIS | scores: {'decoder': -7.989785671234131, 'ctc': -15.783422470092773, 'lm': -35.334617614746094}\n",
      "Prediction 16: I WASN'T REALLY GOING TO WORK LIKE THIS | scores: {'decoder': -9.129656791687012, 'ctc': -20.740808486938477, 'lm': -30.375219345092773}\n",
      "Prediction 17: I WASN'T VERY COOL LOOKING AT THIS | scores: {'decoder': -7.204955101013184, 'ctc': -15.507941246032715, 'lm': -37.94775390625}\n",
      "Prediction 18: I WASN'T VERY COOL LOOKING AT THINGS | scores: {'decoder': -7.301064968109131, 'ctc': -17.515201568603516, 'lm': -37.17258071899414}\n",
      "Prediction 19: I WASN'T QUITE SURE WHAT I THOUGHT | scores: {'decoder': -11.114295959472656, 'ctc': -30.204313278198242, 'lm': -22.046428680419922}\n",
      "Prediction 20: I WASN'T VERY GOOD AT LOOKING AT THINGS | scores: {'decoder': -9.336394309997559, 'ctc': -28.403884887695312, 'lm': -29.286203384399414}\n",
      "Prediction 21: I WASN'T REALLY AT ALL LOOKING AT THINGS | scores: {'decoder': -8.954678535461426, 'ctc': -23.347461700439453, 'lm': -32.43412399291992}\n",
      "Prediction 22: I WASN'T VERY GOOD AT WORKING AT THIS | scores: {'decoder': -7.655624866485596, 'ctc': -26.399303436279297, 'lm': -35.4277229309082}\n",
      "Prediction 23: IT WASN'T REALLY WHAT WE LIKED FIRST | scores: {'decoder': -7.6519880294799805, 'ctc': -23.08587646484375, 'lm': -36.812923431396484}\n",
      "Prediction 24: IT WASN'T A VERY LONG WAY LIKE THIS | scores: {'decoder': -9.50333023071289, 'ctc': -18.754858016967773, 'lm': -32.7570915222168}\n",
      "Prediction 25: IT WASN'T VERY GOOD AT ALL LIKE THIS | scores: {'decoder': -9.589012145996094, 'ctc': -19.924287796020508, 'lm': -32.6346435546875}\n",
      "Prediction 26: IT WASN'T REALLY ALL WE HAD AT FIRST | scores: {'decoder': -8.737004280090332, 'ctc': -23.599599838256836, 'lm': -34.37411880493164}\n",
      "Prediction 27: I WASN'T VERY GOOD AT ALL LIKE THIS | scores: {'decoder': -9.432125091552734, 'ctc': -20.727277755737305, 'lm': -34.48853302001953}\n",
      "Prediction 28: IT WASN'T VERY COOL WE LIKED THOSE | scores: {'decoder': -6.6721720695495605, 'ctc': -18.714874267578125, 'lm': -44.24308395385742}\n",
      "Prediction 29: I WASN'T REALLY AT ALL LOOKING AT THIS | scores: {'decoder': -9.814351081848145, 'ctc': -21.3402042388916, 'lm': -35.16865539550781}\n",
      "Prediction 30: I WASN'T QUITE SURE WHAT I HAD FOUND | scores: {'decoder': -11.424745559692383, 'ctc': -36.21653747558594, 'lm': -25.597387313842773}\n",
      "Prediction 31: IT WASN'T VERY COOL WE LIKED THIS | scores: {'decoder': -8.296425819396973, 'ctc': -16.223106384277344, 'lm': -41.723670959472656}\n",
      "Prediction 32: I WASN'T VERY GOOD AT LOOKING AT THIS | scores: {'decoder': -10.75497055053711, 'ctc': -26.396629333496094, 'lm': -32.18913269042969}\n",
      "Prediction 33: IT WASN'T FOR A QUARTER OR A THIRD | scores: {'decoder': -10.006332397460938, 'ctc': -30.76691436767578, 'lm': -34.1581916809082}\n",
      "Prediction 34: I WASN'T TRYING TO LOOK AT ALL LIKE THIS | scores: {'decoder': -10.588763236999512, 'ctc': -27.64638328552246, 'lm': -33.672821044921875}\n",
      "Prediction 35: I WASN'T VERY GOOD AT LOOKING AT THESE | scores: {'decoder': -10.683406829833984, 'ctc': -30.262069702148438, 'lm': -33.193748474121094}\n",
      "Prediction 36: IT WASN'T FOR A QUARTER OF WHAT I FELT | scores: {'decoder': -9.589492797851562, 'ctc': -31.841108322143555, 'lm': -36.680442810058594}\n",
      "Prediction 37: IT WASN'T FOR A QUARTER OF AN HOUR | scores: {'decoder': -14.505624771118164, 'ctc': -37.75700759887695, 'lm': -23.414112091064453}\n",
      "Prediction 38: IT WASN'T FOR A QUARTER OF A YEAR | scores: {'decoder': -14.140775680541992, 'ctc': -33.15593719482422, 'lm': -26.6142520904541}\n",
      "Prediction 39: IT WASN'T FOR A QUARTER OF WHAT I THOUGHT | scores: {'decoder': -12.531037330627441, 'ctc': -33.566749572753906, 'lm': -34.755985260009766}\n",
      "Prediction 40: IT WASN'T FOR A QUARTER OF AN HOUR FIRST | scores: {'decoder': -12.980192184448242, 'ctc': -40.9482307434082, 'lm': -31.57179069519043}\n",
      "Prediction 41: IT WASN'T FOR A QUARTER OF AN HOUR LIKE THIS | scores: {'decoder': -13.130480766296387, 'ctc': -39.4271240234375, 'lm': -32.333919525146484}\n",
      "Prediction 42: IT WASN'T FOR A QUARTER OF WHAT I FOUND | scores: {'decoder': -12.181299209594727, 'ctc': -33.45777130126953, 'lm': -37.366554260253906}\n",
      "Prediction 43: IT WASN'T FOR A QUARTER OF A YEAR'S | scores: {'decoder': -12.537863731384277, 'ctc': -41.36502456665039, 'lm': -35.91934585571289}\n",
      "Prediction 44: IT WASN'T FOR A QUARTER OF A YEAR IN ADVANCE | scores: {'decoder': -13.413040161132812, 'ctc': -43.270076751708984, 'lm': -34.94353485107422}\n",
      "Prediction 45: IT WASN'T FOR A QUARTER OF AN HOUR AT FIRST | scores: {'decoder': -13.902352333068848, 'ctc': -45.55815505981445, 'lm': -33.615509033203125}\n",
      "Prediction 46: IT WASN'T FOR A QUARTER OF A YEAR OR SO | scores: {'decoder': -14.617032051086426, 'ctc': -49.39548873901367, 'lm': -30.394872665405273}\n",
      "Prediction 47: IT WASN'T FOR A QUARTER OF AN HOUR'S | scores: {'decoder': -14.067789077758789, 'ctc': -46.107112884521484, 'lm': -33.783050537109375}\n",
      "Prediction 48: IT WASN'T FOR A QUARTER OF A YEAR THAT | scores: {'decoder': -15.023066520690918, 'ctc': -36.55390167236328, 'lm': -34.31364440917969}\n",
      "Prediction 49: IT WASN'T FOR A QUARTER OF AN HOUR OR SO | scores: {'decoder': -15.691539764404297, 'ctc': -54.59705352783203, 'lm': -26.708925247192383}\n",
      "Prediction 50: IT WASN'T FOR A QUARTER OF AN HOUR IN ADVANCE | scores: {'decoder': -13.594067573547363, 'ctc': -48.66016387939453, 'lm': -35.256954193115234}\n",
      "Prediction 51: IT WASN'T FOR A QUARTER OF AN HOUR THAT | scores: {'decoder': -15.94593620300293, 'ctc': -42.390926361083984, 'lm': -31.11334800720215}\n",
      "Prediction 52: IT WASN'T FOR A QUARTER OF WHAT HE HAD FOUND | scores: {'decoder': -14.020586013793945, 'ctc': -41.49314880371094, 'lm': -39.182411193847656}\n",
      "Prediction 53: IT WASN'T FOR A QUARTER OR A THIRD OF THIS | scores: {'decoder': -13.012553215026855, 'ctc': -36.90101623535156, 'lm': -43.87826919555664}\n",
      "Prediction 54: IT WASN'T FOR A QUARTER OF WHAT I HAD FOUND | scores: {'decoder': -14.087761878967285, 'ctc': -39.6323356628418, 'lm': -39.758968353271484}\n",
      "Prediction 55: IT WASN'T FOR A QUARTER OR A THIRD OF US | scores: {'decoder': -12.937642097473145, 'ctc': -41.24894332885742, 'lm': -42.67621994018555}\n",
      "Prediction 56: IT WASN'T FOR A QUARTER OR A THIRD OF IT | scores: {'decoder': -14.204503059387207, 'ctc': -43.14631652832031, 'lm': -38.52560806274414}\n",
      "Prediction 57: IT WASN'T FOR A QUARTER OF A YEAR OR TWO | scores: {'decoder': -15.593244552612305, 'ctc': -53.45357131958008, 'lm': -31.16437530517578}\n",
      "Prediction 58: IT WASN'T FOR A QUARTER OR A THIRD OF THOSE | scores: {'decoder': -12.468710899353027, 'ctc': -39.39290237426758, 'lm': -45.368778228759766}\n",
      "Prediction 59: IT WASN'T FOR A QUARTER OF WHAT I HAD FELT | scores: {'decoder': -14.368051528930664, 'ctc': -38.015682220458984, 'lm': -40.448604583740234}\n",
      "Prediction 60: IT WASN'T FOR A QUARTER OF AN HOUR'S FAST | scores: {'decoder': -13.701656341552734, 'ctc': -54.066532135009766, 'lm': -37.39936828613281}\n",
      "Prediction 61: IT WASN'T FOR A QUARTER OF WHAT HE HAD FIRST | scores: {'decoder': -13.44815444946289, 'ctc': -37.830535888671875, 'lm': -43.59846496582031}\n",
      "Prediction 62: IT WASN'T FOR A QUARTER OF WHAT HE HAD FELT | scores: {'decoder': -14.72085952758789, 'ctc': -39.87649154663086, 'lm': -39.77703094482422}\n",
      "Prediction 63: IT WASN'T FOR A QUARTER OF WHAT I HAD FIRST | scores: {'decoder': -14.299118041992188, 'ctc': -35.9697265625, 'lm': -42.54100036621094}\n",
      "Prediction 64: IT WASN'T FOR A QUARTER OF AN HOUR'S NOTICE | scores: {'decoder': -14.689650535583496, 'ctc': -60.623008728027344, 'lm': -35.012210845947266}\n",
      "Prediction 65: IT WASN'T FOR A QUARTER OF AN HOUR AT THIS | scores: {'decoder': -16.157968521118164, 'ctc': -43.15795135498047, 'lm': -36.90022659301758}\n",
      "Prediction 66: IT WASN'T FOR A QUARTER OR A HALF A YARDS | scores: {'decoder': -13.854799270629883, 'ctc': -46.63872146606445, 'lm': -42.784420013427734}\n",
      "Prediction 67: IT WASN'T FOR A QUARTER OF WHAT I'D FOUND | scores: {'decoder': -14.807045936584473, 'ctc': -46.64607238769531, 'lm': -40.3989372253418}\n",
      "Prediction 68: IT WASN'T FOR A QUARTER OF WHAT HE HAD TO DO | scores: {'decoder': -15.796551704406738, 'ctc': -49.043235778808594, 'lm': -37.24493408203125}\n",
      "Prediction 69: IT WASN'T FOR A QUARTER OF A YEAR'S NOTICE | scores: {'decoder': -15.115140914916992, 'ctc': -55.46340560913086, 'lm': -37.27817916870117}\n",
      "Prediction 70: IT WASN'T FOR A QUARTER OR A THIRD OF THAT | scores: {'decoder': -15.543222427368164, 'ctc': -40.78123474121094, 'lm': -41.19367599487305}\n",
      "Prediction 71: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR | scores: {'decoder': -15.182941436767578, 'ctc': -51.28948974609375, 'lm': -38.817291259765625}\n",
      "Prediction 72: IT WASN'T FOR A QUARTER OR A THIRD OF AN HOUR | scores: {'decoder': -15.6865234375, 'ctc': -56.54325485229492, 'lm': -36.272369384765625}\n",
      "Prediction 73: IT WASN'T FOR A QUARTER OR A THIRD OF THE ANSWER | scores: {'decoder': -13.92807388305664, 'ctc': -48.05986022949219, 'lm': -44.90692901611328}\n",
      "Prediction 74: IT WASN'T FOR A QUARTER OF WHAT I'D FELT | scores: {'decoder': -15.720915794372559, 'ctc': -45.02946853637695, 'lm': -40.789649963378906}\n",
      "Prediction 75: IT WASN'T FOR A QUARTER OF WHAT HE HAD TO ASK | scores: {'decoder': -15.946328163146973, 'ctc': -49.584144592285156, 'lm': -38.988277435302734}\n",
      "Prediction 76: IT WASN'T FOR A QUARTER OF A YEAR'S YEAR | scores: {'decoder': -15.745006561279297, 'ctc': -52.10149002075195, 'lm': -39.780128479003906}\n",
      "Prediction 77: IT WASN'T FOR A QUARTER OR A THIRD OF AN INCH | scores: {'decoder': -15.041238784790039, 'ctc': -61.21622848510742, 'lm': -39.62990951538086}\n",
      "Prediction 78: IT WASN'T FOR A QUARTER OF WHAT I'D DONE | scores: {'decoder': -17.846967697143555, 'ctc': -49.860660552978516, 'lm': -35.716312408447266}\n",
      "Prediction 79: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END | scores: {'decoder': -17.550222396850586, 'ctc': -56.54229736328125, 'lm': -34.92564392089844}\n",
      "Prediction 80: IT WASN'T FOR A QUARTER OR A THIRD OF A YEAR | scores: {'decoder': -17.410472869873047, 'ctc': -51.92967224121094, 'lm': -37.3927116394043}\n",
      "Prediction 81: IT WASN'T FOR A QUARTER OR A THIRD OF ITS | scores: {'decoder': -15.382587432861328, 'ctc': -45.087059020996094, 'lm': -47.31833267211914}\n",
      "Prediction 82: IT WASN'T FOR A QUARTER OR A THIRD OF AN HOUR'S | scores: {'decoder': -14.408140182495117, 'ctc': -64.98663330078125, 'lm': -46.47547149658203}\n",
      "Prediction 83: IT WASN'T FOR A QUARTER OF A YEAR'S SALES | scores: {'decoder': -17.159454345703125, 'ctc': -60.57625961303711, 'lm': -41.20962142944336}\n",
      "Prediction 84: IT WASN'T FOR A QUARTER OR A THIRD OF A YEAR'S | scores: {'decoder': -15.969440460205078, 'ctc': -60.397823333740234, 'lm': -45.779579162597656}\n",
      "Prediction 85: IT WASN'T FOR A QUARTER OF A YEAR'S YEAR'S | scores: {'decoder': -16.12386703491211, 'ctc': -64.45601654052734, 'lm': -44.45628356933594}\n",
      "Prediction 86: IT WASN'T FOR A QUARTER OF A YEAR'S VASE | scores: {'decoder': -15.595983505249023, 'ctc': -55.87422180175781, 'lm': -49.603633880615234}\n",
      "Prediction 87: IT WASN'T FOR A QUARTER OF A YEAR'S SALE | scores: {'decoder': -18.40386199951172, 'ctc': -62.07624053955078, 'lm': -39.7404670715332}\n",
      "Prediction 88: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THIS | scores: {'decoder': -18.706037521362305, 'ctc': -63.1043815612793, 'lm': -41.5163688659668}\n",
      "Prediction 89: IT WASN'T FOR A QUARTER OF A YEAR'S SALARY | scores: {'decoder': -20.795942306518555, 'ctc': -65.66072845458984, 'lm': -35.613258361816406}\n",
      "Prediction 90: IT WASN'T FOR A QUARTER OF AN HOUR'S FASTEST | scores: {'decoder': -18.184375762939453, 'ctc': -62.631011962890625, 'lm': -46.31793212890625}\n",
      "Prediction 91: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR'S | scores: {'decoder': -18.521018981933594, 'ctc': -60.03593826293945, 'lm': -46.498695373535156}\n",
      "Prediction 92: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR SO | scores: {'decoder': -18.5870304107666, 'ctc': -59.66850280761719, 'lm': -47.47416305541992}\n",
      "Prediction 93: IT WASN'T FOR A QUARTER OF WHAT I'D DONE TO | scores: {'decoder': -19.370790481567383, 'ctc': -57.31513595581055, 'lm': -45.910926818847656}\n",
      "Prediction 94: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR THAT | scores: {'decoder': -19.75565528869629, 'ctc': -59.12146759033203, 'lm': -44.49601364135742}\n",
      "Prediction 95: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR IT | scores: {'decoder': -18.957515716552734, 'ctc': -58.507259368896484, 'lm': -47.426963806152344}\n",
      "Prediction 96: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR THIS | scores: {'decoder': -19.01923179626465, 'ctc': -56.35585021972656, 'lm': -48.534645080566406}\n",
      "Prediction 97: IT WASN'T FOR A QUARTER OF WHAT HE HAD TO DO WITH | scores: {'decoder': -21.243057250976562, 'ctc': -59.688575744628906, 'lm': -40.809974670410156}\n",
      "Prediction 98: IT WASN'T FOR A QUARTER OR A THIRD OF AN HOUR SO | scores: {'decoder': -18.940292358398438, 'ctc': -64.68576049804688, 'lm': -46.750877380371094}\n",
      "Prediction 99: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE DAY | scores: {'decoder': -20.243579864501953, 'ctc': -77.70458221435547, 'lm': -38.86249542236328}\n",
      "Prediction 100: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THAT | scores: {'decoder': -21.015901565551758, 'ctc': -66.98411560058594, 'lm': -40.314796447753906}\n",
      "Prediction 101: IT WASN'T FOR A QUARTER OR A THIRD OF AN HOUR OR SO | scores: {'decoder': -20.114473342895508, 'ctc': -75.50065612792969, 'lm': -40.40620040893555}\n",
      "Prediction 102: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF | scores: {'decoder': -21.904281616210938, 'ctc': -64.8475112915039, 'lm': -38.811126708984375}\n",
      "Prediction 103: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR IT WAS | scores: {'decoder': -19.406085968017578, 'ctc': -67.79974365234375, 'lm': -45.5458984375}\n",
      "Prediction 104: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF LAST | scores: {'decoder': -20.44977378845215, 'ctc': -69.34209442138672, 'lm': -42.13754653930664}\n",
      "Prediction 105: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE | scores: {'decoder': -20.41132354736328, 'ctc': -68.16194152832031, 'lm': -42.73558807373047}\n",
      "Prediction 106: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE YEAR | scores: {'decoder': -19.771392822265625, 'ctc': -77.50932312011719, 'lm': -42.389888763427734}\n",
      "Prediction 107: IT WASN'T FOR A QUARTER OR A THIRD OF AN HOUR'S TIME | scores: {'decoder': -19.34147834777832, 'ctc': -74.80269622802734, 'lm': -44.857757568359375}\n",
      "Prediction 108: IT WASN'T FOR A QUARTER OR A THIRD OF THE YEAR IT'S | scores: {'decoder': -18.893692016601562, 'ctc': -68.53938293457031, 'lm': -48.309635162353516}\n",
      "Prediction 109: IT WASN'T FOR A QUARTER OF WHAT I'D DONE TO YOU | scores: {'decoder': -22.411855697631836, 'ctc': -63.2213249206543, 'lm': -40.558753967285156}\n",
      "Prediction 110: IT WASN'T FOR A QUARTER OF A YEAR'S VASES | scores: {'decoder': -20.669973373413086, 'ctc': -60.243839263916016, 'lm': -47.46653747558594}\n",
      "Prediction 111: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF IT | scores: {'decoder': -22.936382293701172, 'ctc': -69.34027099609375, 'lm': -37.665191650390625}\n",
      "Prediction 112: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE HOUR | scores: {'decoder': -20.820037841796875, 'ctc': -79.39608764648438, 'lm': -41.84098434448242}\n",
      "Prediction 113: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE AFTERNOON | scores: {'decoder': -21.332338333129883, 'ctc': -78.39175415039062, 'lm': -41.52371597290039}\n",
      "Prediction 114: IT WASN'T FOR A QUARTER OR A THIRD OF A YEAR IT WAS | scores: {'decoder': -21.140583038330078, 'ctc': -68.10245513916016, 'lm': -45.53683853149414}\n",
      "Prediction 115: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE RACE | scores: {'decoder': -21.323415756225586, 'ctc': -76.33985900878906, 'lm': -42.24825668334961}\n",
      "Prediction 116: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE LAST | scores: {'decoder': -20.661544799804688, 'ctc': -73.66597747802734, 'lm': -45.25817108154297}\n",
      "Prediction 117: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE WEEK | scores: {'decoder': -21.74088478088379, 'ctc': -80.34507751464844, 'lm': -39.804893493652344}\n",
      "Prediction 118: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE NIGHT | scores: {'decoder': -21.61948585510254, 'ctc': -76.84397888183594, 'lm': -41.64876174926758}\n",
      "Prediction 119: IT WASN'T FOR A QUARTER OF A YEAR'S YEAR IT WAS | scores: {'decoder': -21.1853084564209, 'ctc': -67.4374008178711, 'lm': -46.448150634765625}\n",
      "Prediction 120: IT WASN'T FOR A QUARTER OR A THIRD OF A YEAR IT'S | scores: {'decoder': -20.331619262695312, 'ctc': -68.82275390625, 'lm': -48.56324768066406}\n",
      "Prediction 121: IT WASN'T FOR A QUARTER OF A YEAR'S YEAR'S YEAR | scores: {'decoder': -20.137739181518555, 'ctc': -75.19975280761719, 'lm': -47.82241439819336}\n",
      "Prediction 122: IT WASN'T FOR A QUARTER OF A YEAR'S VASS | scores: {'decoder': -21.439302444458008, 'ctc': -57.507869720458984, 'lm': -50.005863189697266}\n",
      "Prediction 123: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THOSE | scores: {'decoder': -21.847551345825195, 'ctc': -65.59628295898438, 'lm': -46.13852310180664}\n",
      "Prediction 124: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE TUNNEL | scores: {'decoder': -21.377031326293945, 'ctc': -79.60028076171875, 'lm': -43.26153564453125}\n",
      "Prediction 125: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE INTERVIEW | scores: {'decoder': -22.324661254882812, 'ctc': -76.23645782470703, 'lm': -41.616825103759766}\n",
      "Prediction 126: IT WASN'T FOR A QUARTER OR A THIRD OF AN HOUR'S NOTICE | scores: {'decoder': -19.910816192626953, 'ctc': -80.21147155761719, 'lm': -48.31681823730469}\n",
      "Prediction 127: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE MONTH | scores: {'decoder': -22.09705352783203, 'ctc': -81.7248764038086, 'lm': -41.52445602416992}\n",
      "Prediction 128: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE ROAD | scores: {'decoder': -22.632719039916992, 'ctc': -76.20034790039062, 'lm': -42.57490539550781}\n",
      "Prediction 129: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE STICK | scores: {'decoder': -22.133922576904297, 'ctc': -78.42083740234375, 'lm': -44.84681701660156}\n",
      "Prediction 130: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF AN HOUR | scores: {'decoder': -23.49629783630371, 'ctc': -82.77362060546875, 'lm': -40.08294677734375}\n",
      "Prediction 131: IT WASN'T FOR A QUARTER OF AN HOUR AT THE END OF THE FIRST | scores: {'decoder': -23.830490112304688, 'ctc': -69.83297729492188, 'lm': -43.96936798095703}\n",
      "IT WASN'T REALLY ALL LIKE THIS\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model = pipeline.modelmodule.to('cuda')\n",
    "    data = video.to('cuda')\n",
    "    transcript = model(data)\n",
    "    print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 96, 96, 3])\n",
      "torch.Size([60, 96, 96, 3])\n",
      "tensor([[[[118, 103,  94],\n",
      "          [119, 104,  95],\n",
      "          [118, 103,  94],\n",
      "          ...,\n",
      "          [119,  97,  89],\n",
      "          [122, 100,  92],\n",
      "          [124, 102,  94]],\n",
      "\n",
      "         [[119, 104,  95],\n",
      "          [119, 104,  95],\n",
      "          [119, 104,  95],\n",
      "          ...,\n",
      "          [120,  98,  90],\n",
      "          [123, 101,  93],\n",
      "          [124, 102,  94]],\n",
      "\n",
      "         [[120, 103,  95],\n",
      "          [120, 103,  95],\n",
      "          [119, 102,  94],\n",
      "          ...,\n",
      "          [122,  99,  88],\n",
      "          [125, 102,  91],\n",
      "          [126, 103,  92]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[106, 116, 120],\n",
      "          [113, 123, 127],\n",
      "          [100, 108, 115],\n",
      "          ...,\n",
      "          [ 79,  55,  49],\n",
      "          [ 78,  53,  50],\n",
      "          [ 78,  53,  50]],\n",
      "\n",
      "         [[115, 123, 128],\n",
      "          [119, 127, 132],\n",
      "          [110, 115, 123],\n",
      "          ...,\n",
      "          [ 79,  55,  49],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]],\n",
      "\n",
      "         [[107, 115, 120],\n",
      "          [110, 118, 123],\n",
      "          [106, 111, 119],\n",
      "          ...,\n",
      "          [ 78,  54,  48],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]]],\n",
      "\n",
      "\n",
      "        [[[118, 103,  94],\n",
      "          [119, 104,  95],\n",
      "          [118, 103,  94],\n",
      "          ...,\n",
      "          [119,  97,  89],\n",
      "          [122, 100,  92],\n",
      "          [124, 102,  94]],\n",
      "\n",
      "         [[119, 104,  95],\n",
      "          [119, 104,  95],\n",
      "          [119, 104,  95],\n",
      "          ...,\n",
      "          [120,  98,  90],\n",
      "          [123, 101,  93],\n",
      "          [124, 102,  94]],\n",
      "\n",
      "         [[120, 103,  95],\n",
      "          [120, 103,  95],\n",
      "          [119, 102,  94],\n",
      "          ...,\n",
      "          [122,  99,  88],\n",
      "          [125, 102,  91],\n",
      "          [126, 103,  92]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[106, 116, 120],\n",
      "          [113, 123, 127],\n",
      "          [100, 108, 115],\n",
      "          ...,\n",
      "          [ 79,  55,  49],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]],\n",
      "\n",
      "         [[115, 123, 128],\n",
      "          [119, 127, 132],\n",
      "          [110, 115, 123],\n",
      "          ...,\n",
      "          [ 78,  54,  48],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]],\n",
      "\n",
      "         [[107, 115, 120],\n",
      "          [110, 118, 123],\n",
      "          [106, 111, 119],\n",
      "          ...,\n",
      "          [ 78,  54,  48],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]]],\n",
      "\n",
      "\n",
      "        [[[118, 103,  94],\n",
      "          [119, 104,  95],\n",
      "          [118, 103,  94],\n",
      "          ...,\n",
      "          [119,  97,  89],\n",
      "          [122, 100,  92],\n",
      "          [124, 102,  94]],\n",
      "\n",
      "         [[119, 104,  95],\n",
      "          [119, 104,  95],\n",
      "          [119, 104,  95],\n",
      "          ...,\n",
      "          [120,  98,  90],\n",
      "          [123, 101,  93],\n",
      "          [124, 102,  94]],\n",
      "\n",
      "         [[120, 103,  95],\n",
      "          [120, 103,  95],\n",
      "          [119, 102,  94],\n",
      "          ...,\n",
      "          [122,  99,  88],\n",
      "          [125, 102,  91],\n",
      "          [126, 103,  92]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[114, 122, 127],\n",
      "          [118, 126, 131],\n",
      "          [107, 112, 120],\n",
      "          ...,\n",
      "          [ 79,  55,  49],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]],\n",
      "\n",
      "         [[108, 116, 121],\n",
      "          [115, 123, 128],\n",
      "          [110, 115, 123],\n",
      "          ...,\n",
      "          [ 78,  54,  48],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]],\n",
      "\n",
      "         [[108, 116, 121],\n",
      "          [110, 118, 123],\n",
      "          [105, 110, 118],\n",
      "          ...,\n",
      "          [ 78,  54,  48],\n",
      "          [ 77,  52,  49],\n",
      "          [ 77,  52,  49]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[116, 101,  92],\n",
      "          [115, 100,  91],\n",
      "          [114,  99,  90],\n",
      "          ...,\n",
      "          [132, 104,  93],\n",
      "          [137, 106,  96],\n",
      "          [138, 107,  97]],\n",
      "\n",
      "         [[116, 101,  92],\n",
      "          [115, 100,  91],\n",
      "          [114,  99,  90],\n",
      "          ...,\n",
      "          [132, 104,  93],\n",
      "          [137, 106,  96],\n",
      "          [138, 107,  97]],\n",
      "\n",
      "         [[116,  99,  91],\n",
      "          [115,  98,  90],\n",
      "          [114,  97,  89],\n",
      "          ...,\n",
      "          [134, 103,  93],\n",
      "          [137, 104,  95],\n",
      "          [138, 105,  96]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[104, 114, 118],\n",
      "          [ 92, 102, 106],\n",
      "          [ 97, 109, 115],\n",
      "          ...,\n",
      "          [ 55,  37,  32],\n",
      "          [ 45,  27,  24],\n",
      "          [ 46,  28,  25]],\n",
      "\n",
      "         [[111, 121, 125],\n",
      "          [102, 112, 116],\n",
      "          [ 92, 104, 110],\n",
      "          ...,\n",
      "          [ 50,  32,  27],\n",
      "          [ 43,  25,  22],\n",
      "          [ 50,  32,  29]],\n",
      "\n",
      "         [[113, 123, 127],\n",
      "          [106, 116, 120],\n",
      "          [ 86,  98, 104],\n",
      "          ...,\n",
      "          [ 49,  31,  26],\n",
      "          [ 43,  25,  22],\n",
      "          [ 52,  34,  31]]],\n",
      "\n",
      "\n",
      "        [[[116, 101,  92],\n",
      "          [115, 100,  91],\n",
      "          [114,  99,  90],\n",
      "          ...,\n",
      "          [131, 103,  92],\n",
      "          [136, 105,  95],\n",
      "          [138, 107,  97]],\n",
      "\n",
      "         [[116, 101,  92],\n",
      "          [115, 100,  91],\n",
      "          [114,  99,  90],\n",
      "          ...,\n",
      "          [131, 103,  92],\n",
      "          [136, 105,  95],\n",
      "          [138, 107,  97]],\n",
      "\n",
      "         [[116,  99,  91],\n",
      "          [115,  98,  90],\n",
      "          [114,  97,  89],\n",
      "          ...,\n",
      "          [133, 102,  92],\n",
      "          [136, 105,  95],\n",
      "          [137, 106,  96]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[103, 113, 117],\n",
      "          [ 90, 100, 104],\n",
      "          [ 95, 107, 113],\n",
      "          ...,\n",
      "          [ 51,  35,  29],\n",
      "          [ 42,  29,  24],\n",
      "          [ 49,  36,  31]],\n",
      "\n",
      "         [[110, 120, 124],\n",
      "          [101, 111, 115],\n",
      "          [ 91, 103, 109],\n",
      "          ...,\n",
      "          [ 48,  32,  26],\n",
      "          [ 43,  30,  25],\n",
      "          [ 56,  43,  38]],\n",
      "\n",
      "         [[111, 121, 125],\n",
      "          [104, 114, 118],\n",
      "          [ 85,  97, 103],\n",
      "          ...,\n",
      "          [ 48,  32,  26],\n",
      "          [ 46,  33,  28],\n",
      "          [ 62,  49,  44]]],\n",
      "\n",
      "\n",
      "        [[[116, 101,  92],\n",
      "          [115, 100,  91],\n",
      "          [114,  99,  90],\n",
      "          ...,\n",
      "          [132, 104,  93],\n",
      "          [138, 107,  97],\n",
      "          [140, 109,  99]],\n",
      "\n",
      "         [[116, 101,  92],\n",
      "          [115, 100,  91],\n",
      "          [114,  99,  90],\n",
      "          ...,\n",
      "          [131, 103,  92],\n",
      "          [137, 106,  96],\n",
      "          [139, 108,  98]],\n",
      "\n",
      "         [[116,  99,  91],\n",
      "          [115,  98,  90],\n",
      "          [114,  97,  89],\n",
      "          ...,\n",
      "          [133, 102,  92],\n",
      "          [134, 103,  93],\n",
      "          [136, 105,  95]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[104, 114, 118],\n",
      "          [ 92, 102, 106],\n",
      "          [ 95, 107, 113],\n",
      "          ...,\n",
      "          [ 47,  34,  27],\n",
      "          [ 43,  30,  25],\n",
      "          [ 60,  47,  42]],\n",
      "\n",
      "         [[109, 119, 123],\n",
      "          [100, 110, 114],\n",
      "          [ 91, 103, 109],\n",
      "          ...,\n",
      "          [ 45,  32,  25],\n",
      "          [ 45,  32,  27],\n",
      "          [ 73,  60,  55]],\n",
      "\n",
      "         [[109, 119, 123],\n",
      "          [102, 112, 116],\n",
      "          [ 84,  96, 102],\n",
      "          ...,\n",
      "          [ 43,  30,  23],\n",
      "          [ 46,  33,  28],\n",
      "          [ 82,  69,  64]]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.load('original.pth')\n",
    "print(t1.shape)\n",
    "\n",
    "t2 = torch.load('temp.pth')\n",
    "print(t2.shape)\n",
    "\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658880\n",
      "tensor(1441631)\n"
     ]
    }
   ],
   "source": [
    "not_eq = (t1 != t2)\n",
    "print(t1.numel())\n",
    "print(not_eq.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "dict_keys(['AH', 'EY', 'F', 'AO', 'R', 'T', 'UW', 'W', 'N', 'IH', 'P', 'L', 'AA', 'B', 'ER', 'G', 'K', 'S', 'EH', 'TH', 'M', 'D', 'V', 'Z', 'IY', 'AE', 'OW', 'NG', 'SH', 'HH', 'AW', 'AY', 'JH', 'Y', 'CH', 'ZH', 'UH', 'DH', 'OY'])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "\n",
    "cmu_dict = cmudict.dict()\n",
    "\n",
    "unique_phonemes = defaultdict(int)\n",
    "\n",
    "for i, (w, p) in enumerate(cmu_dict.items()):\n",
    "    phoenemes = p[0]\n",
    "    for ph in phoenemes:\n",
    "        if len(ph) == 3:\n",
    "            unique_phonemes[ph[:2]] += 1\n",
    "        else:\n",
    "            unique_phonemes[ph] += 1\n",
    "\n",
    "print(len(unique_phonemes.keys()))\n",
    "print(unique_phonemes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'playdate' is not in cmu_dict\n",
      "1 412\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_text(text):\n",
    "    punctuation = string.punctuation.replace(\"'\", \"\")\n",
    "    text = text.translate(str.maketrans('', '', punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# dictionary for storing the phoneme frequencies\n",
    "phoeneme_freq = dict()\n",
    "for ph in unique_phonemes.keys():\n",
    "    phoeneme_freq[ph] = 0\n",
    "\n",
    "sentences = open('./vocabs/claude-sentences.txt').readlines()\n",
    "for sentence in sentences:\n",
    "    text = preprocess_text(sentence).split()\n",
    "    for word in text:\n",
    "        if word in cmu_dict.keys():\n",
    "            p = cmu_dict[word][0]\n",
    "            for ph in p:\n",
    "                if len(ph) == 3:\n",
    "                    phoeneme_freq[ph[:2]] += 1\n",
    "                else:\n",
    "                    phoeneme_freq[ph] += 1\n",
    "        else:\n",
    "            print(f\"'{word}' is not in cmu_dict\")\n",
    "\n",
    "freq = phoeneme_freq.values()\n",
    "print(min(freq), max(freq))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "ax.bar(phoeneme_freq.keys(), phoeneme_freq.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_text(text):\n",
    "    punctuation = string.punctuation.replace(\"'\", \"\")\n",
    "    text = text.translate(str.maketrans('', '', punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# dictionary for storing the phoneme frequencies\n",
    "phoeneme_freq = dict()\n",
    "for ph in unique_phonemes.keys():\n",
    "    phoeneme_freq[ph] = 0\n",
    "\n",
    "sentences = open('./vocabs/test-sentences-gpt.txt').readlines()\n",
    "for sentence in sentences:\n",
    "    text = preprocess_text(sentence).split()\n",
    "    for word in text:\n",
    "        if word in cmu_dict.keys():\n",
    "            p = cmu_dict[word][0]\n",
    "            for ph in p:\n",
    "                if len(ph) == 3:\n",
    "                    phoeneme_freq[ph[:2]] += 1\n",
    "                else:\n",
    "                    phoeneme_freq[ph] += 1\n",
    "        else:\n",
    "            print(f\"'{word}' is not in cmu_dict\")\n",
    "\n",
    "freq = phoeneme_freq.values()\n",
    "print(min(freq), max(freq))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "ax.bar(phoeneme_freq.keys(), phoeneme_freq.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some magic so that the notebook will reload external python modules;\n",
    "# see https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import hydra\n",
    "import cv2\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "\n",
    "from datamodule.av_dataset import cut_or_pad\n",
    "from datamodule.transforms import AudioTransform, VideoTransform\n",
    "from hydra import initialize, compose\n",
    "from utils.finetune_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning_grid import ModelModule\n",
    "\n",
    "from datamodule.transforms import TextTransform\n",
    "from espnet.nets.pytorch_backend.e2e_asr_transformer import E2E\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'omegaconf.dictconfig.DictConfig'>\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"configs\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.data.modality = 'video'\n",
    "    cfg.pretrained_model_path = \"./checkpoints/lrs3/models/LRS3_V_WER19.1/model.pth\"\n",
    "\n",
    "print(type(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = TextTransform()\n",
    "token_list = text_transform.token_list\n",
    "backbone_args = cfg.model.visual_backbone\n",
    "\n",
    "model = E2E(len(token_list), backbone_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2E(\n",
      "  (encoder): Encoder(\n",
      "    (frontend): Conv3dResNet(\n",
      "      (trunk): ResNet(\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): Swish()\n",
      "            (relu2): Swish()\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "      )\n",
      "      (frontend3D): Sequential(\n",
      "        (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Swish()\n",
      "        (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (embed): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=768, bias=True)\n",
      "      (1): RelPositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (encoders): MultiSequential(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (6): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (7): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (8): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (9): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (10): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (11): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_pos): Linear(in_features=768, out_features=768, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_cov1): Conv1d(768, 1536, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(768, 768, kernel_size=(31,), stride=(1,), padding=(15,), groups=768)\n",
      "          (norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_cov2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm_ff_macaron): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embed): Sequential(\n",
      "      (0): Embedding(5049, 768)\n",
      "      (1): PositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (decoders): MultiSequential(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (output_layer): Linear(in_features=768, out_features=5049, bias=True)\n",
      "  )\n",
      "  (criterion): LabelSmoothingLoss(\n",
      "    (criterion): KLDivLoss()\n",
      "  )\n",
      "  (ctc): CTC(\n",
      "    (ctc_lo): Linear(in_features=768, out_features=5049, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (ctc_loss): CTCLoss()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTC(\n",
      "  (ctc_lo): Linear(in_features=768, out_features=5049, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (ctc_loss): CTCLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.frontend.trunk.layer1.0.conv1.weight True\n",
      "encoder.frontend.trunk.layer1.0.bn1.weight True\n",
      "encoder.frontend.trunk.layer1.0.bn1.bias True\n",
      "encoder.frontend.trunk.layer1.0.conv2.weight True\n",
      "encoder.frontend.trunk.layer1.0.bn2.weight True\n",
      "encoder.frontend.trunk.layer1.0.bn2.bias True\n",
      "encoder.frontend.trunk.layer1.1.conv1.weight True\n",
      "encoder.frontend.trunk.layer1.1.bn1.weight True\n",
      "encoder.frontend.trunk.layer1.1.bn1.bias True\n",
      "encoder.frontend.trunk.layer1.1.conv2.weight True\n",
      "encoder.frontend.trunk.layer1.1.bn2.weight True\n",
      "encoder.frontend.trunk.layer1.1.bn2.bias True\n",
      "encoder.frontend.trunk.layer2.0.conv1.weight True\n",
      "encoder.frontend.trunk.layer2.0.bn1.weight True\n",
      "encoder.frontend.trunk.layer2.0.bn1.bias True\n",
      "encoder.frontend.trunk.layer2.0.conv2.weight True\n",
      "encoder.frontend.trunk.layer2.0.bn2.weight True\n",
      "encoder.frontend.trunk.layer2.0.bn2.bias True\n",
      "encoder.frontend.trunk.layer2.0.downsample.0.weight True\n",
      "encoder.frontend.trunk.layer2.0.downsample.1.weight True\n",
      "encoder.frontend.trunk.layer2.0.downsample.1.bias True\n",
      "encoder.frontend.trunk.layer2.1.conv1.weight True\n",
      "encoder.frontend.trunk.layer2.1.bn1.weight True\n",
      "encoder.frontend.trunk.layer2.1.bn1.bias True\n",
      "encoder.frontend.trunk.layer2.1.conv2.weight True\n",
      "encoder.frontend.trunk.layer2.1.bn2.weight True\n",
      "encoder.frontend.trunk.layer2.1.bn2.bias True\n",
      "encoder.frontend.trunk.layer3.0.conv1.weight True\n",
      "encoder.frontend.trunk.layer3.0.bn1.weight True\n",
      "encoder.frontend.trunk.layer3.0.bn1.bias True\n",
      "encoder.frontend.trunk.layer3.0.conv2.weight True\n",
      "encoder.frontend.trunk.layer3.0.bn2.weight True\n",
      "encoder.frontend.trunk.layer3.0.bn2.bias True\n",
      "encoder.frontend.trunk.layer3.0.downsample.0.weight True\n",
      "encoder.frontend.trunk.layer3.0.downsample.1.weight True\n",
      "encoder.frontend.trunk.layer3.0.downsample.1.bias True\n",
      "encoder.frontend.trunk.layer3.1.conv1.weight True\n",
      "encoder.frontend.trunk.layer3.1.bn1.weight True\n",
      "encoder.frontend.trunk.layer3.1.bn1.bias True\n",
      "encoder.frontend.trunk.layer3.1.conv2.weight True\n",
      "encoder.frontend.trunk.layer3.1.bn2.weight True\n",
      "encoder.frontend.trunk.layer3.1.bn2.bias True\n",
      "encoder.frontend.trunk.layer4.0.conv1.weight True\n",
      "encoder.frontend.trunk.layer4.0.bn1.weight True\n",
      "encoder.frontend.trunk.layer4.0.bn1.bias True\n",
      "encoder.frontend.trunk.layer4.0.conv2.weight True\n",
      "encoder.frontend.trunk.layer4.0.bn2.weight True\n",
      "encoder.frontend.trunk.layer4.0.bn2.bias True\n",
      "encoder.frontend.trunk.layer4.0.downsample.0.weight True\n",
      "encoder.frontend.trunk.layer4.0.downsample.1.weight True\n",
      "encoder.frontend.trunk.layer4.0.downsample.1.bias True\n",
      "encoder.frontend.trunk.layer4.1.conv1.weight True\n",
      "encoder.frontend.trunk.layer4.1.bn1.weight True\n",
      "encoder.frontend.trunk.layer4.1.bn1.bias True\n",
      "encoder.frontend.trunk.layer4.1.conv2.weight True\n",
      "encoder.frontend.trunk.layer4.1.bn2.weight True\n",
      "encoder.frontend.trunk.layer4.1.bn2.bias True\n",
      "encoder.frontend.frontend3D.0.weight True\n",
      "encoder.frontend.frontend3D.1.weight True\n",
      "encoder.frontend.frontend3D.1.bias True\n",
      "encoder.embed.0.weight True\n",
      "encoder.embed.0.bias True\n",
      "encoder.encoders.0.self_attn.pos_bias_u True\n",
      "encoder.encoders.0.self_attn.pos_bias_v True\n",
      "encoder.encoders.0.self_attn.linear_q.weight True\n",
      "encoder.encoders.0.self_attn.linear_q.bias True\n",
      "encoder.encoders.0.self_attn.linear_k.weight True\n",
      "encoder.encoders.0.self_attn.linear_k.bias True\n",
      "encoder.encoders.0.self_attn.linear_v.weight True\n",
      "encoder.encoders.0.self_attn.linear_v.bias True\n",
      "encoder.encoders.0.self_attn.linear_out.weight True\n",
      "encoder.encoders.0.self_attn.linear_out.bias True\n",
      "encoder.encoders.0.self_attn.linear_pos.weight True\n",
      "encoder.encoders.0.feed_forward.w_1.weight True\n",
      "encoder.encoders.0.feed_forward.w_1.bias True\n",
      "encoder.encoders.0.feed_forward.w_2.weight True\n",
      "encoder.encoders.0.feed_forward.w_2.bias True\n",
      "encoder.encoders.0.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.0.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.0.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.0.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.0.conv_module.norm.weight True\n",
      "encoder.encoders.0.conv_module.norm.bias True\n",
      "encoder.encoders.0.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.0.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.0.norm_ff.weight True\n",
      "encoder.encoders.0.norm_ff.bias True\n",
      "encoder.encoders.0.norm_mha.weight True\n",
      "encoder.encoders.0.norm_mha.bias True\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.0.norm_ff_macaron.weight True\n",
      "encoder.encoders.0.norm_ff_macaron.bias True\n",
      "encoder.encoders.0.norm_conv.weight True\n",
      "encoder.encoders.0.norm_conv.bias True\n",
      "encoder.encoders.0.norm_final.weight True\n",
      "encoder.encoders.0.norm_final.bias True\n",
      "encoder.encoders.1.self_attn.pos_bias_u True\n",
      "encoder.encoders.1.self_attn.pos_bias_v True\n",
      "encoder.encoders.1.self_attn.linear_q.weight True\n",
      "encoder.encoders.1.self_attn.linear_q.bias True\n",
      "encoder.encoders.1.self_attn.linear_k.weight True\n",
      "encoder.encoders.1.self_attn.linear_k.bias True\n",
      "encoder.encoders.1.self_attn.linear_v.weight True\n",
      "encoder.encoders.1.self_attn.linear_v.bias True\n",
      "encoder.encoders.1.self_attn.linear_out.weight True\n",
      "encoder.encoders.1.self_attn.linear_out.bias True\n",
      "encoder.encoders.1.self_attn.linear_pos.weight True\n",
      "encoder.encoders.1.feed_forward.w_1.weight True\n",
      "encoder.encoders.1.feed_forward.w_1.bias True\n",
      "encoder.encoders.1.feed_forward.w_2.weight True\n",
      "encoder.encoders.1.feed_forward.w_2.bias True\n",
      "encoder.encoders.1.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.1.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.1.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.1.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.1.conv_module.norm.weight True\n",
      "encoder.encoders.1.conv_module.norm.bias True\n",
      "encoder.encoders.1.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.1.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.1.norm_ff.weight True\n",
      "encoder.encoders.1.norm_ff.bias True\n",
      "encoder.encoders.1.norm_mha.weight True\n",
      "encoder.encoders.1.norm_mha.bias True\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.1.norm_ff_macaron.weight True\n",
      "encoder.encoders.1.norm_ff_macaron.bias True\n",
      "encoder.encoders.1.norm_conv.weight True\n",
      "encoder.encoders.1.norm_conv.bias True\n",
      "encoder.encoders.1.norm_final.weight True\n",
      "encoder.encoders.1.norm_final.bias True\n",
      "encoder.encoders.2.self_attn.pos_bias_u True\n",
      "encoder.encoders.2.self_attn.pos_bias_v True\n",
      "encoder.encoders.2.self_attn.linear_q.weight True\n",
      "encoder.encoders.2.self_attn.linear_q.bias True\n",
      "encoder.encoders.2.self_attn.linear_k.weight True\n",
      "encoder.encoders.2.self_attn.linear_k.bias True\n",
      "encoder.encoders.2.self_attn.linear_v.weight True\n",
      "encoder.encoders.2.self_attn.linear_v.bias True\n",
      "encoder.encoders.2.self_attn.linear_out.weight True\n",
      "encoder.encoders.2.self_attn.linear_out.bias True\n",
      "encoder.encoders.2.self_attn.linear_pos.weight True\n",
      "encoder.encoders.2.feed_forward.w_1.weight True\n",
      "encoder.encoders.2.feed_forward.w_1.bias True\n",
      "encoder.encoders.2.feed_forward.w_2.weight True\n",
      "encoder.encoders.2.feed_forward.w_2.bias True\n",
      "encoder.encoders.2.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.2.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.2.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.2.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.2.conv_module.norm.weight True\n",
      "encoder.encoders.2.conv_module.norm.bias True\n",
      "encoder.encoders.2.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.2.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.2.norm_ff.weight True\n",
      "encoder.encoders.2.norm_ff.bias True\n",
      "encoder.encoders.2.norm_mha.weight True\n",
      "encoder.encoders.2.norm_mha.bias True\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.2.norm_ff_macaron.weight True\n",
      "encoder.encoders.2.norm_ff_macaron.bias True\n",
      "encoder.encoders.2.norm_conv.weight True\n",
      "encoder.encoders.2.norm_conv.bias True\n",
      "encoder.encoders.2.norm_final.weight True\n",
      "encoder.encoders.2.norm_final.bias True\n",
      "encoder.encoders.3.self_attn.pos_bias_u True\n",
      "encoder.encoders.3.self_attn.pos_bias_v True\n",
      "encoder.encoders.3.self_attn.linear_q.weight True\n",
      "encoder.encoders.3.self_attn.linear_q.bias True\n",
      "encoder.encoders.3.self_attn.linear_k.weight True\n",
      "encoder.encoders.3.self_attn.linear_k.bias True\n",
      "encoder.encoders.3.self_attn.linear_v.weight True\n",
      "encoder.encoders.3.self_attn.linear_v.bias True\n",
      "encoder.encoders.3.self_attn.linear_out.weight True\n",
      "encoder.encoders.3.self_attn.linear_out.bias True\n",
      "encoder.encoders.3.self_attn.linear_pos.weight True\n",
      "encoder.encoders.3.feed_forward.w_1.weight True\n",
      "encoder.encoders.3.feed_forward.w_1.bias True\n",
      "encoder.encoders.3.feed_forward.w_2.weight True\n",
      "encoder.encoders.3.feed_forward.w_2.bias True\n",
      "encoder.encoders.3.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.3.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.3.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.3.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.3.conv_module.norm.weight True\n",
      "encoder.encoders.3.conv_module.norm.bias True\n",
      "encoder.encoders.3.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.3.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.3.norm_ff.weight True\n",
      "encoder.encoders.3.norm_ff.bias True\n",
      "encoder.encoders.3.norm_mha.weight True\n",
      "encoder.encoders.3.norm_mha.bias True\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.3.norm_ff_macaron.weight True\n",
      "encoder.encoders.3.norm_ff_macaron.bias True\n",
      "encoder.encoders.3.norm_conv.weight True\n",
      "encoder.encoders.3.norm_conv.bias True\n",
      "encoder.encoders.3.norm_final.weight True\n",
      "encoder.encoders.3.norm_final.bias True\n",
      "encoder.encoders.4.self_attn.pos_bias_u True\n",
      "encoder.encoders.4.self_attn.pos_bias_v True\n",
      "encoder.encoders.4.self_attn.linear_q.weight True\n",
      "encoder.encoders.4.self_attn.linear_q.bias True\n",
      "encoder.encoders.4.self_attn.linear_k.weight True\n",
      "encoder.encoders.4.self_attn.linear_k.bias True\n",
      "encoder.encoders.4.self_attn.linear_v.weight True\n",
      "encoder.encoders.4.self_attn.linear_v.bias True\n",
      "encoder.encoders.4.self_attn.linear_out.weight True\n",
      "encoder.encoders.4.self_attn.linear_out.bias True\n",
      "encoder.encoders.4.self_attn.linear_pos.weight True\n",
      "encoder.encoders.4.feed_forward.w_1.weight True\n",
      "encoder.encoders.4.feed_forward.w_1.bias True\n",
      "encoder.encoders.4.feed_forward.w_2.weight True\n",
      "encoder.encoders.4.feed_forward.w_2.bias True\n",
      "encoder.encoders.4.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.4.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.4.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.4.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.4.conv_module.norm.weight True\n",
      "encoder.encoders.4.conv_module.norm.bias True\n",
      "encoder.encoders.4.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.4.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.4.norm_ff.weight True\n",
      "encoder.encoders.4.norm_ff.bias True\n",
      "encoder.encoders.4.norm_mha.weight True\n",
      "encoder.encoders.4.norm_mha.bias True\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.4.norm_ff_macaron.weight True\n",
      "encoder.encoders.4.norm_ff_macaron.bias True\n",
      "encoder.encoders.4.norm_conv.weight True\n",
      "encoder.encoders.4.norm_conv.bias True\n",
      "encoder.encoders.4.norm_final.weight True\n",
      "encoder.encoders.4.norm_final.bias True\n",
      "encoder.encoders.5.self_attn.pos_bias_u True\n",
      "encoder.encoders.5.self_attn.pos_bias_v True\n",
      "encoder.encoders.5.self_attn.linear_q.weight True\n",
      "encoder.encoders.5.self_attn.linear_q.bias True\n",
      "encoder.encoders.5.self_attn.linear_k.weight True\n",
      "encoder.encoders.5.self_attn.linear_k.bias True\n",
      "encoder.encoders.5.self_attn.linear_v.weight True\n",
      "encoder.encoders.5.self_attn.linear_v.bias True\n",
      "encoder.encoders.5.self_attn.linear_out.weight True\n",
      "encoder.encoders.5.self_attn.linear_out.bias True\n",
      "encoder.encoders.5.self_attn.linear_pos.weight True\n",
      "encoder.encoders.5.feed_forward.w_1.weight True\n",
      "encoder.encoders.5.feed_forward.w_1.bias True\n",
      "encoder.encoders.5.feed_forward.w_2.weight True\n",
      "encoder.encoders.5.feed_forward.w_2.bias True\n",
      "encoder.encoders.5.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.5.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.5.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.5.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.5.conv_module.norm.weight True\n",
      "encoder.encoders.5.conv_module.norm.bias True\n",
      "encoder.encoders.5.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.5.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.5.norm_ff.weight True\n",
      "encoder.encoders.5.norm_ff.bias True\n",
      "encoder.encoders.5.norm_mha.weight True\n",
      "encoder.encoders.5.norm_mha.bias True\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.5.norm_ff_macaron.weight True\n",
      "encoder.encoders.5.norm_ff_macaron.bias True\n",
      "encoder.encoders.5.norm_conv.weight True\n",
      "encoder.encoders.5.norm_conv.bias True\n",
      "encoder.encoders.5.norm_final.weight True\n",
      "encoder.encoders.5.norm_final.bias True\n",
      "encoder.encoders.6.self_attn.pos_bias_u True\n",
      "encoder.encoders.6.self_attn.pos_bias_v True\n",
      "encoder.encoders.6.self_attn.linear_q.weight True\n",
      "encoder.encoders.6.self_attn.linear_q.bias True\n",
      "encoder.encoders.6.self_attn.linear_k.weight True\n",
      "encoder.encoders.6.self_attn.linear_k.bias True\n",
      "encoder.encoders.6.self_attn.linear_v.weight True\n",
      "encoder.encoders.6.self_attn.linear_v.bias True\n",
      "encoder.encoders.6.self_attn.linear_out.weight True\n",
      "encoder.encoders.6.self_attn.linear_out.bias True\n",
      "encoder.encoders.6.self_attn.linear_pos.weight True\n",
      "encoder.encoders.6.feed_forward.w_1.weight True\n",
      "encoder.encoders.6.feed_forward.w_1.bias True\n",
      "encoder.encoders.6.feed_forward.w_2.weight True\n",
      "encoder.encoders.6.feed_forward.w_2.bias True\n",
      "encoder.encoders.6.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.6.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.6.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.6.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.6.conv_module.norm.weight True\n",
      "encoder.encoders.6.conv_module.norm.bias True\n",
      "encoder.encoders.6.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.6.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.6.norm_ff.weight True\n",
      "encoder.encoders.6.norm_ff.bias True\n",
      "encoder.encoders.6.norm_mha.weight True\n",
      "encoder.encoders.6.norm_mha.bias True\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.6.norm_ff_macaron.weight True\n",
      "encoder.encoders.6.norm_ff_macaron.bias True\n",
      "encoder.encoders.6.norm_conv.weight True\n",
      "encoder.encoders.6.norm_conv.bias True\n",
      "encoder.encoders.6.norm_final.weight True\n",
      "encoder.encoders.6.norm_final.bias True\n",
      "encoder.encoders.7.self_attn.pos_bias_u True\n",
      "encoder.encoders.7.self_attn.pos_bias_v True\n",
      "encoder.encoders.7.self_attn.linear_q.weight True\n",
      "encoder.encoders.7.self_attn.linear_q.bias True\n",
      "encoder.encoders.7.self_attn.linear_k.weight True\n",
      "encoder.encoders.7.self_attn.linear_k.bias True\n",
      "encoder.encoders.7.self_attn.linear_v.weight True\n",
      "encoder.encoders.7.self_attn.linear_v.bias True\n",
      "encoder.encoders.7.self_attn.linear_out.weight True\n",
      "encoder.encoders.7.self_attn.linear_out.bias True\n",
      "encoder.encoders.7.self_attn.linear_pos.weight True\n",
      "encoder.encoders.7.feed_forward.w_1.weight True\n",
      "encoder.encoders.7.feed_forward.w_1.bias True\n",
      "encoder.encoders.7.feed_forward.w_2.weight True\n",
      "encoder.encoders.7.feed_forward.w_2.bias True\n",
      "encoder.encoders.7.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.7.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.7.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.7.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.7.conv_module.norm.weight True\n",
      "encoder.encoders.7.conv_module.norm.bias True\n",
      "encoder.encoders.7.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.7.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.7.norm_ff.weight True\n",
      "encoder.encoders.7.norm_ff.bias True\n",
      "encoder.encoders.7.norm_mha.weight True\n",
      "encoder.encoders.7.norm_mha.bias True\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.7.norm_ff_macaron.weight True\n",
      "encoder.encoders.7.norm_ff_macaron.bias True\n",
      "encoder.encoders.7.norm_conv.weight True\n",
      "encoder.encoders.7.norm_conv.bias True\n",
      "encoder.encoders.7.norm_final.weight True\n",
      "encoder.encoders.7.norm_final.bias True\n",
      "encoder.encoders.8.self_attn.pos_bias_u True\n",
      "encoder.encoders.8.self_attn.pos_bias_v True\n",
      "encoder.encoders.8.self_attn.linear_q.weight True\n",
      "encoder.encoders.8.self_attn.linear_q.bias True\n",
      "encoder.encoders.8.self_attn.linear_k.weight True\n",
      "encoder.encoders.8.self_attn.linear_k.bias True\n",
      "encoder.encoders.8.self_attn.linear_v.weight True\n",
      "encoder.encoders.8.self_attn.linear_v.bias True\n",
      "encoder.encoders.8.self_attn.linear_out.weight True\n",
      "encoder.encoders.8.self_attn.linear_out.bias True\n",
      "encoder.encoders.8.self_attn.linear_pos.weight True\n",
      "encoder.encoders.8.feed_forward.w_1.weight True\n",
      "encoder.encoders.8.feed_forward.w_1.bias True\n",
      "encoder.encoders.8.feed_forward.w_2.weight True\n",
      "encoder.encoders.8.feed_forward.w_2.bias True\n",
      "encoder.encoders.8.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.8.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.8.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.8.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.8.conv_module.norm.weight True\n",
      "encoder.encoders.8.conv_module.norm.bias True\n",
      "encoder.encoders.8.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.8.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.8.norm_ff.weight True\n",
      "encoder.encoders.8.norm_ff.bias True\n",
      "encoder.encoders.8.norm_mha.weight True\n",
      "encoder.encoders.8.norm_mha.bias True\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.8.norm_ff_macaron.weight True\n",
      "encoder.encoders.8.norm_ff_macaron.bias True\n",
      "encoder.encoders.8.norm_conv.weight True\n",
      "encoder.encoders.8.norm_conv.bias True\n",
      "encoder.encoders.8.norm_final.weight True\n",
      "encoder.encoders.8.norm_final.bias True\n",
      "encoder.encoders.9.self_attn.pos_bias_u True\n",
      "encoder.encoders.9.self_attn.pos_bias_v True\n",
      "encoder.encoders.9.self_attn.linear_q.weight True\n",
      "encoder.encoders.9.self_attn.linear_q.bias True\n",
      "encoder.encoders.9.self_attn.linear_k.weight True\n",
      "encoder.encoders.9.self_attn.linear_k.bias True\n",
      "encoder.encoders.9.self_attn.linear_v.weight True\n",
      "encoder.encoders.9.self_attn.linear_v.bias True\n",
      "encoder.encoders.9.self_attn.linear_out.weight True\n",
      "encoder.encoders.9.self_attn.linear_out.bias True\n",
      "encoder.encoders.9.self_attn.linear_pos.weight True\n",
      "encoder.encoders.9.feed_forward.w_1.weight True\n",
      "encoder.encoders.9.feed_forward.w_1.bias True\n",
      "encoder.encoders.9.feed_forward.w_2.weight True\n",
      "encoder.encoders.9.feed_forward.w_2.bias True\n",
      "encoder.encoders.9.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.9.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.9.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.9.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.9.conv_module.norm.weight True\n",
      "encoder.encoders.9.conv_module.norm.bias True\n",
      "encoder.encoders.9.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.9.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.9.norm_ff.weight True\n",
      "encoder.encoders.9.norm_ff.bias True\n",
      "encoder.encoders.9.norm_mha.weight True\n",
      "encoder.encoders.9.norm_mha.bias True\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.9.norm_ff_macaron.weight True\n",
      "encoder.encoders.9.norm_ff_macaron.bias True\n",
      "encoder.encoders.9.norm_conv.weight True\n",
      "encoder.encoders.9.norm_conv.bias True\n",
      "encoder.encoders.9.norm_final.weight True\n",
      "encoder.encoders.9.norm_final.bias True\n",
      "encoder.encoders.10.self_attn.pos_bias_u True\n",
      "encoder.encoders.10.self_attn.pos_bias_v True\n",
      "encoder.encoders.10.self_attn.linear_q.weight True\n",
      "encoder.encoders.10.self_attn.linear_q.bias True\n",
      "encoder.encoders.10.self_attn.linear_k.weight True\n",
      "encoder.encoders.10.self_attn.linear_k.bias True\n",
      "encoder.encoders.10.self_attn.linear_v.weight True\n",
      "encoder.encoders.10.self_attn.linear_v.bias True\n",
      "encoder.encoders.10.self_attn.linear_out.weight True\n",
      "encoder.encoders.10.self_attn.linear_out.bias True\n",
      "encoder.encoders.10.self_attn.linear_pos.weight True\n",
      "encoder.encoders.10.feed_forward.w_1.weight True\n",
      "encoder.encoders.10.feed_forward.w_1.bias True\n",
      "encoder.encoders.10.feed_forward.w_2.weight True\n",
      "encoder.encoders.10.feed_forward.w_2.bias True\n",
      "encoder.encoders.10.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.10.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.10.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.10.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.10.conv_module.norm.weight True\n",
      "encoder.encoders.10.conv_module.norm.bias True\n",
      "encoder.encoders.10.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.10.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.10.norm_ff.weight True\n",
      "encoder.encoders.10.norm_ff.bias True\n",
      "encoder.encoders.10.norm_mha.weight True\n",
      "encoder.encoders.10.norm_mha.bias True\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.10.norm_ff_macaron.weight True\n",
      "encoder.encoders.10.norm_ff_macaron.bias True\n",
      "encoder.encoders.10.norm_conv.weight True\n",
      "encoder.encoders.10.norm_conv.bias True\n",
      "encoder.encoders.10.norm_final.weight True\n",
      "encoder.encoders.10.norm_final.bias True\n",
      "encoder.encoders.11.self_attn.pos_bias_u True\n",
      "encoder.encoders.11.self_attn.pos_bias_v True\n",
      "encoder.encoders.11.self_attn.linear_q.weight True\n",
      "encoder.encoders.11.self_attn.linear_q.bias True\n",
      "encoder.encoders.11.self_attn.linear_k.weight True\n",
      "encoder.encoders.11.self_attn.linear_k.bias True\n",
      "encoder.encoders.11.self_attn.linear_v.weight True\n",
      "encoder.encoders.11.self_attn.linear_v.bias True\n",
      "encoder.encoders.11.self_attn.linear_out.weight True\n",
      "encoder.encoders.11.self_attn.linear_out.bias True\n",
      "encoder.encoders.11.self_attn.linear_pos.weight True\n",
      "encoder.encoders.11.feed_forward.w_1.weight True\n",
      "encoder.encoders.11.feed_forward.w_1.bias True\n",
      "encoder.encoders.11.feed_forward.w_2.weight True\n",
      "encoder.encoders.11.feed_forward.w_2.bias True\n",
      "encoder.encoders.11.conv_module.pointwise_cov1.weight True\n",
      "encoder.encoders.11.conv_module.pointwise_cov1.bias True\n",
      "encoder.encoders.11.conv_module.depthwise_conv.weight True\n",
      "encoder.encoders.11.conv_module.depthwise_conv.bias True\n",
      "encoder.encoders.11.conv_module.norm.weight True\n",
      "encoder.encoders.11.conv_module.norm.bias True\n",
      "encoder.encoders.11.conv_module.pointwise_cov2.weight True\n",
      "encoder.encoders.11.conv_module.pointwise_cov2.bias True\n",
      "encoder.encoders.11.norm_ff.weight True\n",
      "encoder.encoders.11.norm_ff.bias True\n",
      "encoder.encoders.11.norm_mha.weight True\n",
      "encoder.encoders.11.norm_mha.bias True\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.weight True\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.bias True\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.weight True\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.bias True\n",
      "encoder.encoders.11.norm_ff_macaron.weight True\n",
      "encoder.encoders.11.norm_ff_macaron.bias True\n",
      "encoder.encoders.11.norm_conv.weight True\n",
      "encoder.encoders.11.norm_conv.bias True\n",
      "encoder.encoders.11.norm_final.weight True\n",
      "encoder.encoders.11.norm_final.bias True\n",
      "encoder.after_norm.weight True\n",
      "encoder.after_norm.bias True\n"
     ]
    }
   ],
   "source": [
    "freeze_decoder(model)\n",
    "freeze_ctc(model)\n",
    "for (name, param) in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name, param.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lip-reading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
